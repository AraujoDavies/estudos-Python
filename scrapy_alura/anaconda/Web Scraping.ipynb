{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>1. MEU PRIMEIRO SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Web Scraping* é o termo utilizado para definir a prática de coletar automaticamente informações na Internet. Isto é feito, geralmente, por meio de programas que simulam a navegação humana na Web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Ambiente e bibliotecas\n",
    "### Utilizaremos em nosso treinamento o navegador Google Chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e9pXIMIWByAp"
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import urllib.request as urllib_request\n",
    "import pandas\n",
    "\n",
    "print(\"BeautifulSoup ->\", bs4.__version__)\n",
    "print(\"urllib ->\", urllib_request.__version__)\n",
    "print(\"pandas ->\", pandas.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Meu primeiro scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://alura-site-scraping.herokuapp.com/hello-world.php'\n",
    "\n",
    "response = urlopen(url)\n",
    "html = response.read()\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "print(soup.find('h1', id='hello-world').get_text())\n",
    "print(soup.find('p').get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>2. OBTENDO E TRATANDO O CONTEÚDO DE UM HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Entendendo a web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./web/web.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Obtendo o conteúdo HTML de um site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urllib.request\n",
    "## https://docs.python.org/3/library/urllib.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "c1pKGnTpgvFU",
    "outputId": "b6b7e32d-4c3e-4f52-a8ba-0b1cbfe15ea4"
   },
   "outputs": [],
   "source": [
    "# para obter o html de uma página será usado o URLLIB\n",
    "from urllib.request import Request, urlopen\n",
    "# tratar erros\n",
    "# se for usar ambos é obrigatorio colocar a tratativa do HTTPError primeiro\n",
    "from urllib.error import URLError, HTTPError \n",
    "\n",
    "url1 = 'https://alura-site-scraping.herokuapp.com/index.php'\n",
    "url2 = 'https://www.alura.com.br'\n",
    "\n",
    "response = urlopen(url1) \n",
    "# aqui obtemos o HTML da url1 sem problemas, porém a url2 vai dar o erro => 403: Forbidden\n",
    "html = response.read()\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://docs.python.org/3/library/urllib.request.html#urllib.request.Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Para resolver...\n",
    "# pegar user-agent do navegador\n",
    "resolve403 = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "\n",
    "# tratativas de erros com o try\n",
    "try:\n",
    "    # Request informando User-Agent\n",
    "    req = Request(url2, headers = resolve403)\n",
    "    response = urlopen(req)\n",
    "    print(response.read())\n",
    "\n",
    "except HTTPError as e: # se erro de requisição ele printa\n",
    "    print(e.status, e.reason)\n",
    "except URLError as e: # se erro de URL ele printa getaddrinfo failed\n",
    "    print(e.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Tratamento de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para obter o html de uma página será usado o URLLIB\n",
    "from urllib.request import Request, urlopen\n",
    "# tratar erros\n",
    "# se for usar ambos é obrigatorio colocar a tratativa do HTTPError primeiro\n",
    "from urllib.error import URLError, HTTPError \n",
    "\n",
    "url1 = 'https://alura-site-scraping.herokuapp.com/index.php'\n",
    "url2 = 'https://www.alura.com.br'\n",
    "\n",
    "response = urlopen(url1) \n",
    "# aqui obtemos o HTML da url1 sem problemas, porém a url2 vai dar o erro => 403: Forbidden\n",
    "html = response.read()\n",
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convertando o tipo bytes para string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = html.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando os caracteres de tabulação, quebra de linha etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\" \".join(html.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminando os espaços em branco entre as TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\" \".join(html.split()).replace('> <', '><')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de tratamento de strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_html(input):\n",
    "    return \" \".join(input.split()).replace('> <','><')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trata_html(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsfhL3sZFRZu"
   },
   "source": [
    "---\n",
    "# <font color=green>3. INTRODUÇÃO AO BEAUTIFULSOUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsfhL3sZFRZu"
   },
   "source": [
    "# 3.1. HTML da nossa página"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HTML** (*HyperText Markup Language*) é uma linguagem de marcação composta por **tags** que deteminam o papel que cada parte do documento vai assumir. As **tags** são formadas pelo seu nome e atributos. Os atributos servem para configurar e também modificar as características padrões de uma **tag**.\n",
    "\n",
    "## Estrutura básica\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <meta charset=\"utf-8\" />\n",
    "        <title>Alura Motors</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div id=\"container\">\n",
    "            <h1>Alura</h1>\n",
    "            <h2 class=\"formato\">Cursos de Tecnologia</h2>\n",
    "            <p>Você vai estudar, praticar, discutir e aprender.</p>\n",
    "            <a href=\"https://www.alura.com.br/\">Clique aqui</a>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "```<html>``` - determina o início do documento.\n",
    "\n",
    "```<head>``` - cabeçalho. Contém informações e configurações do documento.\n",
    "\n",
    "```<body>``` - é o corpo do documento, onde todo o conteúdo é colocado. Esta é a parte visível em um navegador.\n",
    "\n",
    "## Tags mais comuns\n",
    "\n",
    "```<div>``` - define uma divisão da página. Pode ser formatada de diversas maneiras.\n",
    "\n",
    "```<h1>, <h2>, <h3>, <h4>, <h5>, <h6>``` - marcadores de títulos.\n",
    "\n",
    "```<p>``` - marcador de parágrafo.\n",
    "\n",
    "```<a>``` - hiperlink.\n",
    "\n",
    "```<img>``` - exibição de imagens.\n",
    "\n",
    "```<table>``` - definição de tabelas.\n",
    "\n",
    "```<ul>, <li>``` - definição de listas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2. Criando um objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://www.crummy.com/software/BeautifulSoup/\n",
    "\n",
    "### Sobre parser ver: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#parser-installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "id": "5Oxx_d0BCWGa",
    "outputId": "4d2c4e2b-57fe-413d-9521-91711e0e5fdc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# criando objeto Beautifulsoup:\n",
    "html = trata_html(html)\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3. Acessando tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.div.div.div.div.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4. Acessando o conteúdo das tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.title.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.h5.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.get_text() # pega todo texto do html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5. Acessando os atributos de uma tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.attrs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img.get('src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <font color=green>4. PESQUISANDO COM O BEAUTIFULSOUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1. Os métodos *find()* e *findAll()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### *find(tag, attributes, recursive, text, **kwargs)*\n",
    "\n",
    "- ### *findAll(tag, attributes, recursive, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all\n",
    "\n",
    "> **Observação:**\n",
    "> - *findAll()* também pode ser utilizado como *find_all()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *find()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Método *findAll()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comando equivalente ao método *find()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('img', limit=2)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atalho para o método *findAll()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passando listas de TAGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(['h1','h2','h3','h4','h5','h6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando o argumento *attributes*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.findAll('p', {'class': 'txt-value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscando por conteúdo de uma TAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p', text = \"Belo Horizonte - MG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando diretamente os atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('img', alt=\"Foto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.findAll('img', alt=\"Foto\"):\n",
    "    print(item.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuidado com o atributo \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all('p', class_='txt-value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo todo o conteúdo de texto de uma página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find_all(text = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2. Outros métodos de pesquisa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### *findParent(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findParents(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-parents-and-find-parent\n",
    "\n",
    "> **Observação:**\n",
    "> - *findParent()* e *findParents()* também podem ser utilizados como *find_parent()* e *find_parents()*, respectivamente.\n",
    "---\n",
    "- ### *findNextSibling(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findNextSiblings(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "- ### *findPreviousSibling(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findPreviousSiblings(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-next-siblings-and-find-next-sibling\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-previous-siblings-and-find-previous-sibling\n",
    "\n",
    "> **Observação:**\n",
    "> - *findNextSibling()*, *findNextSiblings()*, *findPreviousSibling()* e *findPreviousSiblings()* também podem ser utilizados como *find_next_sibling()*, *find_next_siblings()*, *find_previous_sibling()* e *find_previous_siblings()*, respectivamente.\n",
    "---\n",
    "- ### *findNext(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findAllNext(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "- ### *findPrevious(tag, attributes, text, **kwargs)*\n",
    "\n",
    "- ### *findAllPrevious(tag, attributes, text, limit, **kwargs)*\n",
    "\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all-next-and-find-next\n",
    "#### https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all-previous-and-find-previous\n",
    "\n",
    "> **Observação:**\n",
    "> - *findNext()*, *findAllNext()*, *findPrevious* e *findAllPrevious* também podem ser utilizados como *find_next()*, *find_all_next()*, *find_previous()* e *find_all_previous()*, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HTML de exemplo para ilustrar a utilização dos métodos de pesquisa do BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://caelum-online-public.s3.amazonaws.com/1381-scraping/01/BeautifulSoup-method.png\" width=80%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <div id=“container-a”>\n",
    "            <h1>Título A</h1>\n",
    "            <h2 class=\"ref-a\">Sub título A</h2>\n",
    "            <p>Texto de conteúdo A</p>\n",
    "        </div>\n",
    "        <div id=“container-b”>\n",
    "            <h1>Título B</h1>\n",
    "            <h2 class=\"ref-b\">Sub título B</h2>\n",
    "            <p>Texto de conteúdo B</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste = \"\"\"\n",
    "    <html>\n",
    "        <body>\n",
    "            <div id=“container-a”>\n",
    "                <h1>Título A</h1>\n",
    "                <h2 class=\"ref-a\">Sub título A</h2>\n",
    "                <p>Texto de conteúdo A</p>\n",
    "            </div>\n",
    "            <div id=“container-b”>\n",
    "                <h1>Título B</h1>\n",
    "                <h2 class=\"ref-b\">Sub título B</h2>\n",
    "                <p>Texto de conteúdo B</p>\n",
    "            </div>\n",
    "        </body>\n",
    "    </html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamentos para a string HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_teste = trata_html(html_teste)\n",
    "html_teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_teste, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').find_parent('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').find_parents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all('h2').find_parents('div') # da erro pq tem mais de 1 'h2'. como resolver ? olhe abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in soup.find_all('h2'):\n",
    "    print(item.find_parent('div'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findNextSibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findPreviousSibling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('p').findPreviousSibling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next e Previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findNext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findPrevious()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('h2').findAllNext() #findAllPrevious => vai pegar todos anteriores... é meio sem sentido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>5. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE UM ANÚNCIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1. Identificando e selecionando os dados no HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo o HTML e criando o objeto BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = urlopen('https://alura-site-scraping.herokuapp.com/index.php')\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando variávels para armazenar informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = []\n",
    "card = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtendo os dados do primeiro CARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "anuncio = soup.find('div', {'class': 'well card'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2. Obtendo o VALOR do veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncio.find('div', {'class': 'value-card'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncio.find('p', {'class': 'txt-value'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card['value'] = anuncio.find('p', {'class': 'txt-value'}).get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p pegar o Valor eu só preciso disso: \n",
    "card['value'] = anuncio.find('p', {'class': 'txt-value'}).get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3. Obtendo as INFORMAÇÕES sobre o veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncio.find('div', {'class': 'body-card'}).findAll('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infos = anuncio.find('div', {'class': 'body-card'}).findAll('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    print(info.get('class'), '-', info.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    print(info.get('class')[0], '-', info.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    print(info.get('class')[0].split('-'), '-', info.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    print(info.get('class')[0].split('-')[-1], '-', info.get_text()) # [-1] = ultimo item de uma lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in infos:\n",
    "    card[info.get('class')[0].split('-')[-1]] =  info.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações\n",
    "infos = anuncio.find('div', {'class': 'body-card'}).findAll('p')\n",
    "for info in infos:\n",
    "    card[info.get('class')[0].split('-')[-1]] =  info.get_text()\n",
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4. Obtendo os ACESSÓRIOS do veículo anunciado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anuncio.find('div', {'class': 'body-card'}).ul.findAll('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = anuncio.find('div', {'class': 'body-card'}).ul.findAll('li')\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items: \n",
    "    print(item.getText().replace('► ', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acessorios = []\n",
    "for item in items: \n",
    "    acessorios.append(item.getText().replace('► ', ''))\n",
    "acessorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card['items'] = acessorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessórios\n",
    "items = anuncio.find('div', {'class': 'body-card'}).ul.findAll('li')\n",
    "items.pop()\n",
    "acessorios = []\n",
    "\n",
    "for item in items: \n",
    "    acessorios.append(item.getText().replace('► ', ''))\n",
    "\n",
    "card['items'] = acessorios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 Criando um DataFrame com os dados coletados do Alura Motors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # o Pandas faz um tratamento melhor das informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(card) # criando um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset # porém a saída não está como precisamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(card, orient = \"index\")\n",
    "dataset # agora ta do jeito que precisamos, porém está no modo coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colocando em modo linha\n",
    "dataset = pd.DataFrame.from_dict(card, orient = \"index\").T\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv('./output/data/x.csv', sep=';', index=False, encoding='utf-8-sig')\n",
    "# to_csv(\n",
    "# 'local do arquivo', \n",
    "# sep de separar colunas, \n",
    "# indexFalse tira o 0, \n",
    "# enconding para arrumar caracteres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.6. Obtendo a FOTO do anúncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = anuncio.img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.get('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image.get('src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando a FOTO no notebook (extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(str(anuncio.find('div', {'class': 'image-card'}).img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(\"<img src = \" + (anuncio.find('div', {'class': 'image-card'}).img.get('src') + \">\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotina para acessar e salvar a FOTO do anúncio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## https://docs.python.org/3/library/urllib.request.html#urllib.request.urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# malandragem para nomear a foto :D\n",
    "photo_name = image.get('src').split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve # funçãozinha que faz o download \n",
    "\n",
    "urlretrieve(image.get('src'), './output/img/' + photo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>Resumo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importar o urlretrieve\n",
    "# urlretrieve (link_da_img, 'caminho q quero salva-la')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>6. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE TODOS OS ANÚNCIOS DE UMA PÁGINA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1. Identificando as informações no HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(soup.find('div', {'id': 'container-cards'}).findAll('div', class_='card')) # são 10 carros por pagina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "anuncios = soup.find('div', {'id': 'container-cards'}).findAll('div', class_='card')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for anuncio in anuncios:\n",
    "    print(str(anuncio) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2. Criando uma rotina de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Declarando variável cards (uma lista)\n",
    "cards = []\n",
    "\n",
    "# Obtendo o HTML\n",
    "response = urlopen('https://alura-site-scraping.herokuapp.com/index.php')\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Obtendo as TAGs de interesse\n",
    "anuncios = soup.find('div', {\"id\": \"container-cards\"}).findAll('div', class_=\"card\")\n",
    "\n",
    "# Coletando as informações dos CARDS\n",
    "for anuncio in anuncios:\n",
    "    card = {}\n",
    "    \n",
    "    # Valor\n",
    "    card['value'] = anuncio.find('p', {'class': 'txt-value'}).getText()\n",
    "\n",
    "    # Informações\n",
    "    infos = anuncio.find('div', {'class': 'body-card'}).findAll('p')\n",
    "    for info in infos:\n",
    "        card[info.get('class')[0].split('-')[-1]] = info.get_text()\n",
    "\n",
    "    # Acessórios\n",
    "    items = anuncio.find('div', {'class': 'body-card'}).ul.findAll('li')\n",
    "    items.pop()\n",
    "    acessorios = []\n",
    "    for item in items:\n",
    "        acessorios.append(item.get_text().replace('► ', ''))\n",
    "    card['items'] = acessorios\n",
    "    \n",
    "    # Adicionando resultado a lista cards\n",
    "    cards.append(card)\n",
    "\n",
    "    # Imagens\n",
    "    image = anuncio.find('div', {'class': 'image-card'}).img\n",
    "    urlretrieve(image.get('src'), './output/img/' + image.get('src').split('/')[-1])     \n",
    "\n",
    "# Criando um DataFrame com os resultados\n",
    "dataset = pd.DataFrame(cards)\n",
    "dataset.to_csv('./output/data/dataset_onepage.csv', sep=';', index = False, encoding = 'utf-8-sig')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=green>7. WEB SCRAPING DO SITE ALURA MOTORS - OBTENDO OS DADOS DE TODOS OS ANÚNCIOS DO SITE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1. Identificando as informações no HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_=\"info-pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup.find('span', class_=\"info-pages\").getText()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_=\"info-pages\").getText().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.find('span', class_=\"info-pages\").getText().split()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(soup.find('span', class_=\"info-pages\").getText().split()[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2. Criando uma rotina de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "from urllib.request import urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Declarando variável cards\n",
    "cards = []\n",
    "\n",
    "## Obtendo o HTML e o total de páginas\n",
    "response = urlopen('https://alura-site-scraping.herokuapp.com/index.php')\n",
    "html = response.read().decode('utf-8')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "pages = int(soup.find('span', class_=\"info-pages\").get_text().split()[-1])\n",
    "\n",
    "## Iterando por todas as páginas do site\n",
    "for i in range(pages):\n",
    "    ## Obtendo o HTML\n",
    "    response = urlopen('https://alura-site-scraping.herokuapp.com/index.php?page='+str(i+1))\n",
    "    html = response.read().decode('utf-8')\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Obtendo as TAGs de interesse\n",
    "    anuncios = soup.find('div', {\"id\": \"container-cards\"}).findAll('div', class_=\"card\")\n",
    "\n",
    "    # Coletando as informações dos CARDS\n",
    "    for anuncio in anuncios:\n",
    "        card = {}\n",
    "\n",
    "        # Valor\n",
    "        card['value'] = anuncio.find('p', {'class': 'txt-value'}).getText()\n",
    "\n",
    "        # Informações\n",
    "        infos = anuncio.find('div', {'class': 'body-card'}).findAll('p')\n",
    "        for info in infos:\n",
    "                card[info.get('class')[0].split('-')[-1]] = info.get_text()\n",
    "\n",
    "        # Acessórios\n",
    "        items = anuncio.find('div', {'class': 'body-card'}).ul.findAll('li')\n",
    "        items.pop()\n",
    "        acessorios = []\n",
    "        for item in items:\n",
    "            acessorios.append(item.get_text().replace('► ', ''))\n",
    "        card['items'] = acessorios\n",
    "\n",
    "        # Adicionando resultado a lista cards\n",
    "        cards.append(card)\n",
    "\n",
    "        # Imagens\n",
    "        image = anuncio.find('div', {'class': 'image-card'}).img\n",
    "        urlretrieve(image.get('src'), './output/img/' + image.get('src').split('/')[-1])     \n",
    "\n",
    "# Criando um DataFrame com os resultados\n",
    "dataset = pd.DataFrame(cards)\n",
    "dataset.to_csv('./output/data/dataset_fullsite.csv', sep=';', index = False, encoding = 'utf-8-sig')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    print('https://alura-site-scraping.herokuapp.com/index.php?page=' + str(i + 1))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled12.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "73ae350a481fd2b81e12da5f178d258fb7322dc726e3dad938780f34a0668666"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
